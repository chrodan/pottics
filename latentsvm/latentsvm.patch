diff -r -u2 lsvm/svm_struct_latent_api.c lsvm_pottics/svm_struct_latent_api.c
--- lsvm/svm_struct_latent_api.c	2012-06-29 21:09:11.000000000 +0200
+++ lsvm_pottics/svm_struct_latent_api.c	2012-04-23 11:04:36.000000000 +0200
@@ -18,5 +18,65 @@
 #include <assert.h>
 #include "svm_struct_latent_api_types.h"
+#include <math.h>
 
+#define BINARY_PRESCALE 1e-1
+#define UNARY_PRESCALE 1e-1
+#define PROP_EPS 1e-6
+
+static void readBuf32i( FILE * fp, unsigned int size, int * buf ){
+	fread( buf, sizeof(*buf), size, fp );
+	int i=0;
+	for(i=0; i<size; i++ )
+		buf[i] = ntohl( buf[i] );
+}
+static void readBuf16( FILE * fp, unsigned int size, short * buf ){
+	fread( buf, sizeof(*buf), size, fp );
+	int i=0;
+	for(i=0; i<size; i++ )
+		buf[i] = ntohs( buf[i] );
+}
+static void readBuf32f( FILE * fp, unsigned int size, float * buf ){
+	uint32_t* buf2 = (uint32_t*) buf;
+	fread( buf2, sizeof(*buf2), size, fp );
+	int i=0;
+	for(i=0; i<size; i++ )
+		buf2[i] = ntohl( buf2[i] );
+}
+
+void print_region(REGION* r) {
+
+	printf("Region #%i of size %i with %i classes\n  unaries: ", r->id, r->size, r->nclass);
+	int i;
+	for(i=0; i < r->nclass; i++)
+		printf(" %g", r->unaries[i]);
+	printf("\n  segments:");
+	for(i=0; r->segments[i] >= 0; i++)
+		printf(" %i", r->segments[i]);
+
+	printf("\n");
+
+}
+
+void print_parameter(STRUCTMODEL* sm) {
+
+	printf("Parameters: alpha = %.3g\n", sm->w[sm->sizePsi - 1]);
+	int i;
+	for (i=0; i < sm->sizePsi - 1; i++) {
+	  printf("%.2g ", sm->w[i]);
+	  if (i % 21 == 20)
+	    printf("\n");
+        }
+	//printf("\n");
+
+}
+
+void print_label(LABEL* y) {
+
+	printf("Label (%i)", y->nregion);
+	int i;
+	for(i=0; i < y->nregion; i++)
+		printf(" %i", y->rclass[i]);
+	printf("\n");
+}
 
 SAMPLE read_struct_examples(char *file, STRUCT_LEARN_PARM *sparm) {
@@ -28,7 +88,92 @@
 */
   SAMPLE sample;
+  printf("Read data from %s\n", file);
+  FILE* fp = fopen(file, "rb");
+  if (fp==NULL) {
+    printf("Cannot open input file %s!\n", file);
+	exit(1);
+  }
+  int n;
+  int classnum;
+  readBuf32i(fp, 1, &n);
   
-  /* your code here */
 
+  
+  sample.n = n;
+  sample.examples = (EXAMPLE*)malloc(sizeof(EXAMPLE)*n);
+  int i=0;
+  for (i=0;(!feof(fp))&&(i<n);i++) {
+  
+    int j=0;
+    PATTERN* curPattern = &(sample.examples[i].x);
+    LABEL* curLabel = &(sample.examples[i].y);
+
+    for(j=0; (j == 0  || curPattern->image_name[j-1] != 0 ) && (j <999); j++) {
+      fread(&(curPattern->image_name[j]), 1, 1, fp);
+    }
+    readBuf32i(fp, 1, &classnum);
+    readBuf32i(fp, 1, &(curPattern->region_num));
+
+    curPattern->reg_per_seg =  (short*)malloc(sizeof(short)*(sparm->segment_num));
+    curPattern->segments =  (short*)malloc(sizeof(short)*(curPattern->region_num * sparm->segment_num));
+
+    
+    curLabel->nregion = curPattern->region_num;
+    curLabel->rclass =  (int*)malloc(sizeof(int)*(curPattern->region_num));
+    curLabel->rsize =  (int*)malloc(sizeof(int)*(curPattern->region_num));
+
+    int k=0;
+    for (k=0; k < sparm->segment_num; k++)
+    	curPattern->reg_per_seg[k] = 0;
+    for (k=0; k < (curPattern->region_num * sparm->segment_num); k++)
+        curPattern->segments[k] = -1;
+
+    curPattern->regions = (REGION*)malloc(sizeof(REGION)*(curPattern->region_num));
+
+    
+    printf("Process %i regions, %i classes, from image %s\n", curPattern->region_num, classnum, curPattern->image_name);
+
+      // read regions
+      for(k=0; k < curPattern->region_num; k++) {
+        REGION* curRegion = &(curPattern->regions[k]);
+        int rid, rsize, rclass;
+        readBuf32i(fp, 1, &rid);
+        readBuf32i(fp, 1, &rsize);
+        readBuf32i(fp, 1, &rclass);
+
+        curRegion->nclass = classnum;
+        curRegion->id = rid;
+        curRegion->size = rsize;
+
+        curLabel->rsize[k] = rsize;
+        curLabel->rclass[k] =  rclass;
+
+	//printf("Region %i has size, %i and class %i\n", rid, rsize, rclass);
+
+	// read unaries
+	curRegion->unaries = (float*)malloc(sizeof(float)*classnum);
+	//fread(curRegion->unaries, sizeof(float), classnum, fp);
+	readBuf32f(fp, classnum, curRegion->unaries);
+
+	// read region segment structure
+	short* segbuf = (short*)malloc(sizeof(short)*(1 + sparm->segment_num));
+	int l = 0;
+	int pos = 0;
+	for (l=0; (l == 0 || segbuf[l-1] >= 0) && (l < (1 + sparm->segment_num)); l++) {
+	  readBuf16(fp, 1, &(segbuf[l]));
+	  //printf("Segment %i\n", segbuf[l]);
+	  if (segbuf[l] >= 0) {
+	    pos = (curPattern->region_num * segbuf[l]) + curPattern->reg_per_seg[segbuf[l]];
+	    curPattern->segments[pos] = (short)k;
+	    curPattern->reg_per_seg[segbuf[l]]++;
+    	  }
+        }
+        curRegion->segments = segbuf;
+        //print_region(curRegion);
+
+	//print_label(curLabel);
+      }
+  }
+  //print_label(&(sample.examples[0].y));
   return(sample); 
 }
@@ -41,5 +186,5 @@
 */
 
-  sm->sizePsi = 100; /* replace with appropriate number */
+  sm->sizePsi = sparm->topics_num * sparm->class_num + 1; /* replace with appropriate number */
 
   /* your code here*/
@@ -52,6 +197,11 @@
   Latent variables are stored at sample.examples[i].h, for 1<=i<=sample.n.
 */
+  int i,j=0;
+  for (j=0; j < sample->n; j++) {
+    sample->examples[j].h.topics = (short*)malloc(sizeof(short)* sparm->segment_num);
+    for(i=0; i< sparm->segment_num; i++)
+      sample->examples[j].h.topics[i] = rand() % (sparm->topics_num);
+  }
 
-  /* your code here */
 }
 
@@ -62,8 +212,56 @@
   feature vector returned has to agree with the dimension in sm->sizePsi. 
 */
+  //printf("Create feature vector of dimension %i\n", sm->sizePsi);
+
   SVECTOR *fvec=NULL;  
   
   /* your code here */
+  
+  int i, j;
+  int n = sm->sizePsi;
+  WORD psi[n+1];
+  for(i=0; i<n; i++) {
+    psi[i].weight = 0.;
+    psi[i].wnum = i;
+  }
+
+  int num=0;
+  for(i=0; i<x.region_num; i++) {
+    //printf("debug i: %i %i\n", x.region_num, i);
+
+    for (j = 0; x.regions[i].segments[j] >= 0; j++)
+    {
+	int k = h.topics[x.regions[i].segments[j]] * sparm->class_num + y.rclass[i];
+	//printf("%i",y.rclass[i]);
+    //printf("debug j, k, seg: %i %i, %i \n", j, k, x.regions[i].segments[j]);
+	psi[k].weight-=BINARY_PRESCALE;
+	num++;
+    }
+    //printf("debug stopped: %i %i\n", x.region_num, j);
+  }
+  
+  j=0;
+  for(i=0; i<n; i++) {
+    if (psi[i].weight != 0.) {
+      psi[j] = psi[i];
+      j++;
+    }
+  }
 
+  
+  for (i=0; i< x.region_num; i++) {
+    float un = x.regions[i].unaries[(int) y.rclass[i]];
+    if (un <= PROP_EPS) un = PROP_EPS;
+    psi[j].wnum = n-1;
+    psi[j].weight += UNARY_PRESCALE * log(un);
+  }
+  //printf("Nonzero features  #%i \n", j+1);
+  //for (i=0; i < j+1; i++)
+  //  printf("    f_%i = %f \n", psi[i].wnum, psi[i].weight);
+  for (i=j+1; i < n + 1; i++)
+    psi[i].wnum = 0; 
+    psi[i].weight = 0.;
+  fvec = create_svector(psi, "", 1);
+  
   return(fvec);
 }
@@ -78,4 +276,154 @@
   
   /* your code here */  
+  
+  printf("Classify called, deprecated\n");
+  exit(0);
+
+}
+
+float find_latent_variables(PATTERN x, LABEL y, LATENT_VAR* hbar, STRUCTMODEL *sm, STRUCT_LEARN_PARM *sparm) {
+    
+    int i,t, k;
+    float en_tot=0;
+    // optimize topics given region classes
+    for(i=0; i< sparm->segment_num; i++) {
+      short n_reg = x.reg_per_seg[i];
+      short* reglist = x.segments + x.region_num * i;
+      float min_energy = -INFINITY;
+      char best[sparm->topics_num];
+      for(t=0; t < sparm->topics_num; t++) {
+	float energy = 0.;
+	for(k=0; k < n_reg; k++) {
+	  energy -= BINARY_PRESCALE * sm->w[t * sparm->class_num + y.rclass[reglist[k]]];
+	}
+
+	if (energy > min_energy) {
+		//printf("better class %i for region %i with energy %f\n", t, i, energy);
+		min_energy = energy;
+		int s;
+		for (s=0; s<t; s++) best[s] = 0;
+		best[t] = 1;
+	} else if (energy == min_energy) {
+		best[t] = 1;
+	} else { best[t] = 0; }
+      }
+      en_tot += min_energy;
+       // take one minimizer topic at random
+      int s = rand() % (sparm->topics_num);
+      int u=0;
+      for (t=0; t < s + sparm->topics_num; t++) {
+	if (best[u])
+	  hbar->topics[i] = u;
+        u++;
+	u = u % sparm->topics_num;
+      }
+  }
+  return en_tot;
+}
+
+float find_labels(PATTERN x, LABEL*y, LABEL* ybar, LATENT_VAR h, STRUCTMODEL *sm, STRUCT_LEARN_PARM *sparm) {
+  int i, t, k;
+  float en_tot = 0;
+   for(i=0; i< x.region_num; i++) {
+      float min_energy = -INFINITY;
+      REGION* curreg = &(x.regions[i]);
+      char best[curreg->nclass];
+      for(t=0; t < curreg->nclass; t++) {
+	float energy = 0.;
+
+	// unary -energy
+	float un = curreg->unaries[t];
+	if (un <= PROP_EPS) un = PROP_EPS;
+	energy += UNARY_PRESCALE * sm->w[sm->sizePsi - 1] * log(un);
+	// loss
+	if (y != NULL && y->rclass[i] != t) {
+		energy += y->rsize[i];
+	}
+
+	// binary terms
+	for(k=0; curreg->segments[k] >= 0; k++) {
+	  energy -= BINARY_PRESCALE * sm->w[h.topics[curreg->segments[k]] * sparm->class_num + t];
+	}
+
+	if (energy > min_energy) {
+		//printf("better class %i for region %i with energy %f\n", t, i, energy);
+		min_energy = energy;
+		int s;
+		for (s=0; s<t; s++) best[s] = 0;
+		best[t] = 1;
+	} else if (energy == min_energy) {
+		best[t] = 1;
+	} else { best[t] = 0; }
+      }
+      en_tot += min_energy;
+
+      int s = rand() % (curreg->nclass);
+      int u=0;
+      for (t=0; t < s + curreg->nclass; t++) {
+	if (best[u])
+	  ybar->rclass[i] = u;
+        u++;
+	u = u % curreg->nclass;
+      }
+  }
+  return en_tot;
+}
+
+float find_labels_unary_only(PATTERN x, LABEL*y, LABEL* ybar, LATENT_VAR h, STRUCTMODEL *sm, STRUCT_LEARN_PARM *sparm) {
+  int i, t, k;
+  float en_tot = 0;
+   for(i=0; i< x.region_num; i++) {
+      float min_energy = -INFINITY;
+      REGION* curreg = &(x.regions[i]);
+      char best[curreg->nclass];
+      for(t=0; t < curreg->nclass; t++) {
+	float energy = 0.;
+
+	// unary -energy
+	float un = curreg->unaries[t];
+	if (un <= PROP_EPS) un = PROP_EPS;
+	energy += UNARY_PRESCALE * log(un);
+
+
+	if (energy > min_energy) {
+		//printf("better class %i for region %i with energy %f\n", t, i, energy);
+		min_energy = energy;
+		int s;
+		for (s=0; s<t; s++) best[s] = 0;
+		best[t] = 1;
+	} else if (energy == min_energy) {
+		best[t] = 1;
+	} else { best[t] = 0; }
+      }
+      en_tot += min_energy;
+
+      int s = rand() % (curreg->nclass);
+      int u=0;
+      for (t=0; t < s + curreg->nclass; t++) {
+	if (best[u])
+	  ybar->rclass[i] = u;
+        u++;
+	u = u % curreg->nclass;
+      }
+  }
+  return en_tot * sm->w[sm->sizePsi - 1];
+}
+
+double loss(LABEL y, LABEL ybar, LATENT_VAR hbar, STRUCT_LEARN_PARM *sparm) {
+/*
+  Computes the loss of prediction (ybar,hbar) against the
+  correct label y. 
+*/
+  double ans;
+  
+  /* your code here */
+  int i;
+  ans = 0;
+  for(i=0; i < y.nregion; i++) {
+    if (y.rclass[i] != ybar.rclass[i])
+      ans+=y.rsize[i] ;
+  }
+  //printf("Loss: %g\n", ans);
+  return(ans);
 }
 
@@ -89,6 +437,115 @@
 
   /* your code here */
+
+  //printf("find most violated called\n");
+  int i, n=0;
+  LABEL cury;
+  LATENT_VAR curh;
+  float obj = -1e60;
+
+
+// init topics randomly
+
+  hbar->topics = (short*)malloc(sizeof(short)* sparm->segment_num);
+  curh.topics = (short*)malloc(sizeof(short)* sparm->segment_num);
+
+
+  ybar->nregion = y.nregion;
+  ybar->rclass = (int*)malloc(sizeof(int)* x.region_num);
+  ybar->rsize = (int*)malloc(sizeof(int)* x.region_num);
+  for(i=0; i< x.region_num; i++) {
+    ybar->rsize[i] = y.rsize[i];
+    //printf("Size: %i %i\n", i, y.rsize[i]);
+  }
+
+  cury.nregion = y.nregion;
+  cury.rclass = (int*)malloc(sizeof(int)* x.region_num);
+  cury.rsize = (int*)malloc(sizeof(int)* x.region_num);
+  for(i=0; i< x.region_num; i++) {
+    cury.rsize[i] = y.rsize[i];
+  }
+
+  
+  
+  find_labels_unary_only(x, &y, &cury, curh, sm, sparm);
+  int j;
+  for(j=0; j<3; j++) {
+    int l=0;
+    float en = 0;
+    float curen = -1e60;
+    // until convergence
+    while (fabs(en - curen) > 0.001) {
+      l++;
+      en = curen;
+
+      find_latent_variables(x, cury, &curh, sm, sparm);
+      curen = find_labels(x, &y, &cury, curh, sm, sparm);
+    }
+
+    if (curen > obj) {
+      for(i =0; i< x.region_num; i++)
+        ybar->rclass[i] = cury.rclass[i];
+
+      for(i=0; i< sparm->segment_num; i++)
+        hbar->topics[i] = curh.topics[i];
+      
+      obj = curen;
+      n++;
+     }
+     for (i=0; i < sparm->segment_num; i++) {
+      curh.topics[i] = (short)(rand() % (sparm->topics_num));
+      //printf("%i, ", curh.topics[i]);
+     }
+     curen = find_labels(x, &y, &cury, curh, sm, sparm);
+  }
+  free(cury.rclass);
+  free(cury.rsize);
+  free(curh.topics);
+#if (DEBUG_LEVEL>3)
+  float en_un=0, en_lo=0, en_bi=0;
+  for(i =0; i< x.region_num; i++) {
+  
+    // unary
+    float un = x.regions[i].unaries[ybar->rclass[i]];
+    if (un <= PROP_EPS) un = PROP_EPS;
+    en_un += UNARY_PRESCALE * sm->w[sm->sizePsi - 1] * log(un);
+	
+    // loss
+    if (y.rclass[i] != ybar->rclass[i]) {
+      en_lo += y.rsize[i];
+    }
+    int k;
+    for(k=0; x.regions[i].segments[k] >= 0; k++) {
+      en_bi -= BINARY_PRESCALE * sm->w[hbar->topics[x.regions[i].segments[k]] * sparm->class_num + ybar->rclass[i]];
+    }
+  }
+
+  SVECTOR * vec = psi(x, *ybar, *hbar, sm, sparm);
+  float specen = sprod_ns(sm->w,vec);
+  double lss = loss(y, *ybar, *hbar, sparm);
+  free_svector(vec);
+
+  printf("Final energy %g,%g after %i updates (%g, %g, %g, %g)\n", obj - lss, specen, n, en_un, en_bi, en_lo, lss);
+
+
+    // optimize topics given region classes
+    
+    
+
+  //printf("converged %i: %g\n", l+1, curen);
+  //print_label(ybar);
+  //print_parameter(sm);
+    for(i=0; i< 10; i++)
+	printf("%i ", hbar->topics[i]);
+    printf("\n");
+    for(i=0; i< 10; i++)
+	printf("%i ", ybar->rclass[i]);
+    printf("\n");
+	//printf("%.2g ", sm->w[i]);*/
+
+#endif
 }
 
+
 LATENT_VAR infer_latent_variables(PATTERN x, LABEL y, STRUCTMODEL *sm, STRUCT_LEARN_PARM *sparm) {
 /*
@@ -97,23 +554,22 @@
 */
 
+  //printf("infer latent var called\n");
   LATENT_VAR h;
+  h.topics = (short*)malloc(sizeof(short)* sparm->segment_num);
+  find_latent_variables(x, y, &h, sm, sparm);
 
-  /* your code here */
 
+#if (DEBUG_LEVEL>3)
+  int i;
+  printf("h ");
+  for(i=0; i< 10; i++)
+	printf("%i ", h.topics[i]);
+  printf("\n");
+#endif
   return(h); 
 }
 
 
-double loss(LABEL y, LABEL ybar, LATENT_VAR hbar, STRUCT_LEARN_PARM *sparm) {
-/*
-  Computes the loss of prediction (ybar,hbar) against the
-  correct label y. 
-*/
-  double ans;
-  
-  /* your code here */
 
-  return(ans);
-}
 
 void write_struct_model(char *file, STRUCTMODEL *sm, STRUCT_LEARN_PARM *sparm) {
@@ -121,5 +577,23 @@
   Writes the learned weight vector sm->w to file after training. 
 */
- 
+ FILE *modelfl;
+  int i;
+  
+  modelfl = fopen(file,"w");
+  if (modelfl==NULL) {
+    printf("Cannot open model file %s for output!", file);
+	exit(1);
+  }
+  
+  /* write model information */
+  //fprintf(modelfl, "# segments: %i\n", sparm->segment_num);
+  //fprintf(modelfl, "# order of background Markov model: %d\n", sparm->bg_markov_order);
+  fprintf(modelfl, "# alpha prescale\n%.16g\n# binary prescale\n%.16g\n", UNARY_PRESCALE, BINARY_PRESCALE);
+  fprintf(modelfl, "# number of topics\n%i\n", sparm->topics_num);
+  fprintf(modelfl, "# alpha\n%.16g\n# binary features\n", sm->w[sm->sizePsi - 1]);
+  for (i=0;i<sm->sizePsi-1;i++) {
+    fprintf(modelfl, "%.16g\n", sm->w[i]);
+  }
+  fclose(modelfl);
 }
 
@@ -130,6 +604,6 @@
 */
   STRUCTMODEL sm;
+  sm.sizePsi = sparm->topics_num * sparm->class_num + 1;
 
-  /* your code here */
 
   return(sm);
@@ -146,4 +620,10 @@
 }
 
+
+void free_regions(REGION r) {
+  free(r.unaries);
+  free(r.segments);
+}
+
 void free_pattern(PATTERN x) {
 /*
@@ -152,7 +632,15 @@
 
   /* your code here */
+  int i;
+  for (i=0; i<x.region_num; i++) {
+    free_regions(x.regions[i]);
+  }
+  free(x.regions);
+  free(x.segments);
 
+  free(x.reg_per_seg);
 }
 
+
 void free_label(LABEL y) {
 /*
@@ -160,6 +648,6 @@
 */
 
-  /* your code here */
-
+  free(y.rclass);
+  free(y.rsize);
 } 
 
@@ -168,5 +656,5 @@
   Free any memory malloc'ed when creating latent variable h. 
 */
-
+  free(h.topics);
   /* your code here */
 
@@ -195,11 +683,19 @@
   
   /* set default */
-  
+  sparm->segment_num=100;
+  sparm->class_num=21;
+  sparm->topics_num=10;
   for (i=0;(i<sparm->custom_argc)&&((sparm->custom_argv[i])[0]=='-');i++) {
     switch ((sparm->custom_argv[i])[2]) {
       /* your code here */
+      case 't': i++; sparm->topics_num = atoi(sparm->custom_argv[i]);
+      break;
+
+      case 's': i++; sparm->segment_num = atoi(sparm->custom_argv[i]); break;
       default: printf("\nUnrecognized option %s!\n\n", sparm->custom_argv[i]); exit(0);
     }
   }
+
+  printf("#Topics: %i\n", sparm->topics_num);
 }
 
diff -r -u2 lsvm/svm_struct_latent_api_types.h lsvm_pottics/svm_struct_latent_api_types.h
--- lsvm/svm_struct_latent_api_types.h	2012-06-29 21:09:11.000000000 +0200
+++ lsvm_pottics/svm_struct_latent_api_types.h	2012-04-10 19:04:44.000000000 +0200
@@ -17,9 +17,24 @@
 # include "svm_light/svm_common.h"
 
+
+typedef struct region {
+  int id;
+  int size;
+  int nclass;
+  float* unaries;
+  short* segments;
+} REGION;
+
+
 typedef struct pattern {
   /*
     Type definition for input pattern x
   */
-  int add_your_own_variables;
+  int region_num;
+  char image_name[100];
+  REGION* regions;
+
+  short* reg_per_seg;
+  short* segments;
 } PATTERN;
 
@@ -28,5 +43,7 @@
     Type definition for output label y
   */
-  int add_your_own_variables;
+  int nregion;
+  int* rclass;
+  int* rsize;
 } LABEL;
 
@@ -35,5 +52,7 @@
     Type definition for latent variable h
   */
-  int add_your_own_variables;
+  short* topics;
+
+  //short topics;
 } LATENT_VAR;
 
@@ -79,5 +98,7 @@
 				  option */
   /* add your own variables */
-  int your_own_variable; 
+  int topics_num;
+  int segment_num;
+  int class_num;
 } STRUCT_LEARN_PARM;
 
diff -r -u2 lsvm/svm_struct_latent_cccp.c lsvm_pottics/svm_struct_latent_cccp.c
--- lsvm/svm_struct_latent_cccp.c	2012-06-29 21:09:11.000000000 +0200
+++ lsvm_pottics/svm_struct_latent_cccp.c	2012-04-23 11:04:36.000000000 +0200
@@ -34,5 +34,7 @@
 #define MIN(x,y) ((x) > (y) ? (y) : (x))
 
-#define DEBUG_LEVEL 0
+#define DEBUG_LEVEL 10
+
+int iternum=0;
 
 void my_read_input_parameters(int argc, char* argv[], char *trainfile, char *modelfile,
@@ -154,5 +156,4 @@
 double cutting_plane_algorithm(double *w, long m, int MAX_ITER, double C, double epsilon, SVECTOR **fycache, EXAMPLE *ex, STRUCTMODEL *sm, STRUCT_LEARN_PARM *sparm) {
   long i,j;
-  double xi;
   double *alpha;
   double **G; /* Gram matrix */
@@ -163,5 +164,4 @@
   int iter, size_active; 
   double value;
-  int r;
   int *idle; /* for cleaning up */
   double margin;
@@ -242,5 +242,4 @@
   iter = 0;
   size_active = 0;
-  xi = 0.0;
   alpha = NULL;
   G = NULL;
@@ -356,4 +355,7 @@
     }
 
+    
+    print_parameter(sm);
+
     /* compute dual obj */
     dual_obj = +0.5*(1+rho)*sprod_nn(w,w,sm->sizePsi);
@@ -565,5 +567,5 @@
   printf("C: %.8g\n", C);
   printf("epsilon: %.8g\n", epsilon);
-  printf("sample.n: %ld\n", sample.n); 
+  printf("sample.n: %d\n", sample.n);
   printf("sm.sizePsi: %ld\n", sm.sizePsi); fflush(stdout);
   
@@ -591,5 +593,6 @@
     /* cutting plane algorithm */
     primal_obj = cutting_plane_algorithm(w, m, MAX_ITER, C, cooling_eps, fycache, ex, &sm, &sparm); 
-    
+    print_parameter(&sm);
+
     /* compute decrement in objective in this outer iteration */
     decrement = last_primal_obj - primal_obj;
